{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate  0.1901723549474807 ; Hidden dimension  30.0\n",
      "Learning rate per minibatch: 0.1901723549474807\n",
      "      1.4        1.4       0.56       0.56            25\n",
      "    0.844      0.567      0.307       0.18            75\n",
      "    0.705        0.6      0.297       0.29           175\n",
      "    0.609      0.526      0.264      0.235           375\n",
      "    0.543       0.48      0.206      0.152           775\n",
      "    0.473      0.406      0.163       0.12          1575\n",
      "    0.397      0.322      0.132      0.101          3175\n",
      "    0.333      0.268      0.113     0.0953          6375\n",
      "    0.282      0.231     0.0965     0.0797         12775\n",
      "    0.252      0.223     0.0898     0.0831         25575\n",
      " error rate on an unseen minibatch: 0.0\n",
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate  0.199069944589508 ; Hidden dimension  90.0\n",
      "Learning rate per minibatch: 0.199069944589508\n",
      "    0.621      0.621        0.2        0.2            25\n",
      "    0.642      0.653      0.333        0.4            75\n",
      "    0.619      0.602      0.383       0.42           175\n",
      "    0.861       1.07       0.48      0.565           375\n",
      "    0.663      0.478      0.347      0.223           775\n",
      "    0.478      0.298      0.223      0.102          1575\n",
      "    0.365      0.254      0.156     0.0894          3175\n",
      "    0.303      0.241      0.122     0.0878          6375\n",
      "    0.267      0.232      0.104     0.0862         12775\n",
      "    0.243       0.22     0.0917     0.0795         25575\n",
      " error rate on an unseen minibatch: 0.2\n",
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate  0.13129906300867464 ; Hidden dimension  50.0\n",
      "Learning rate per minibatch: 0.13129906300867464\n",
      "    0.668      0.668       0.32       0.32            25\n",
      "     0.72      0.746      0.413       0.46            75\n",
      "     0.74      0.754      0.469       0.51           175\n",
      "    0.668      0.605      0.365      0.275           375\n",
      "    0.593      0.524      0.285       0.21           775\n",
      "    0.496      0.402      0.196       0.11          1575\n",
      "    0.407      0.319      0.145     0.0938          3175\n",
      "    0.331      0.256      0.113     0.0825          6375\n",
      "     0.28       0.23     0.0971     0.0809         12775\n",
      "     0.25      0.219     0.0894     0.0816         25575\n",
      " error rate on an unseen minibatch: 0.04\n",
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate  0.12727113950183994 ; Hidden dimension  60.0\n",
      "Learning rate per minibatch: 0.12727113950183994\n",
      "    0.709      0.709        0.4        0.4            25\n",
      "    0.702      0.698      0.467        0.5            75\n",
      "    0.667      0.641      0.406       0.36           175\n",
      "    0.611      0.562      0.355       0.31           375\n",
      "    0.544      0.481      0.252      0.155           775\n",
      "     0.46      0.379      0.182      0.115          1575\n",
      "    0.387      0.315      0.136       0.09          3175\n",
      "     0.32      0.254      0.106     0.0756          6375\n",
      "    0.273      0.225      0.095     0.0845         12775\n",
      "    0.245      0.218     0.0871     0.0791         25575\n",
      " error rate on an unseen minibatch: 0.0\n",
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate  0.1604865071050303 ; Hidden dimension  40.0\n",
      "Learning rate per minibatch: 0.1604865071050303\n",
      "    0.809      0.809       0.48       0.48            25\n",
      "    0.888      0.927      0.573       0.62            75\n",
      "    0.802      0.738      0.571       0.57           175\n",
      "    0.718      0.644       0.44      0.325           375\n",
      "    0.603      0.495      0.295       0.16           775\n",
      "    0.499      0.399      0.201       0.11          1575\n",
      "    0.421      0.345      0.156      0.111          3175\n",
      "    0.346      0.272      0.122     0.0881          6375\n",
      "    0.287      0.229      0.101     0.0795         12775\n",
      "    0.259       0.23     0.0937     0.0868         25575\n",
      " error rate on an unseen minibatch: 0.04\n",
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate  0.19683389021542091 ; Hidden dimension  80.0\n",
      "Learning rate per minibatch: 0.19683389021542091\n",
      "     0.75       0.75       0.52       0.52            25\n",
      "    0.919          1       0.52       0.52            75\n",
      "    0.936      0.949      0.474       0.44           175\n",
      "    0.732      0.553      0.352      0.245           375\n",
      "    0.575      0.428      0.261      0.175           775\n",
      "    0.436      0.302      0.177      0.095          1575\n",
      "    0.344      0.254       0.13      0.085          3175\n",
      "    0.285      0.226      0.107     0.0844          6375\n",
      "    0.259      0.233     0.0963     0.0853         12775\n",
      "    0.239      0.218     0.0901      0.084         25575\n",
      " error rate on an unseen minibatch: 0.08\n",
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate  0.1641075642549597 ; Hidden dimension  20.0\n",
      "Learning rate per minibatch: 0.1641075642549597\n",
      "     0.89       0.89       0.52       0.52            25\n",
      "    0.742      0.667       0.48       0.46            75\n",
      "    0.679      0.633      0.411       0.36           175\n",
      "    0.629      0.585      0.291      0.185           375\n",
      "    0.567       0.51      0.196      0.107           775\n",
      "    0.515      0.464      0.157       0.12          1575\n",
      "    0.442       0.37      0.126     0.0944          3175\n",
      "    0.368      0.294      0.106     0.0862          6375\n",
      "    0.307      0.246     0.0956     0.0853         12775\n",
      "    0.268       0.23     0.0899     0.0841         25575\n",
      " error rate on an unseen minibatch: 0.12\n",
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate  0.11297036501998742 ; Hidden dimension  80.0\n",
      "Learning rate per minibatch: 0.11297036501998742\n",
      "    0.717      0.717       0.64       0.64            25\n",
      "    0.697      0.687      0.547        0.5            75\n",
      "    0.655      0.624      0.497       0.46           175\n",
      "    0.658      0.661      0.443      0.395           375\n",
      "    0.563      0.474      0.311      0.188           775\n",
      "    0.468      0.375      0.203     0.0988          1575\n",
      "    0.384      0.301      0.151     0.0988          3175\n",
      "    0.317      0.252      0.118      0.085          6375\n",
      "     0.27      0.223     0.0966     0.0756         12775\n",
      "    0.242      0.215      0.088     0.0794         25575\n",
      " error rate on an unseen minibatch: 0.04\n",
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate  0.1825760773972605 ; Hidden dimension  70.0\n",
      "Learning rate per minibatch: 0.1825760773972605\n",
      "    0.659      0.659       0.36       0.36            25\n",
      "    0.648      0.642       0.44       0.48            75\n",
      "     0.74       0.81      0.457       0.47           175\n",
      "    0.597      0.471      0.307      0.175           375\n",
      "    0.535      0.477      0.263      0.223           775\n",
      "    0.413      0.296      0.175     0.0887          1575\n",
      "    0.334      0.256      0.128     0.0819          3175\n",
      "    0.289      0.244       0.11     0.0928          6375\n",
      "     0.26      0.231     0.0975     0.0847         12775\n",
      "    0.239      0.218     0.0896     0.0818         25575\n",
      " error rate on an unseen minibatch: 0.16\n",
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate  0.16499414701760465 ; Hidden dimension  50.0\n",
      "Learning rate per minibatch: 0.16499414701760465\n",
      "    0.798      0.798       0.44       0.44            25\n",
      "    0.759       0.74      0.493       0.52            75\n",
      "     0.72       0.69      0.491       0.49           175\n",
      "    0.663      0.614      0.371      0.265           375\n",
      "    0.587      0.517      0.295      0.225           775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0.492      0.399      0.215      0.138          1575\n",
      "    0.407      0.324       0.16      0.106          3175\n",
      "    0.335      0.263      0.126     0.0922          6375\n",
      "    0.285      0.236      0.107     0.0886         12775\n",
      "    0.251      0.217      0.094     0.0808         25575\n",
      " error rate on an unseen minibatch: 0.0\n",
      "{'hd': 30.0, 'lr': 0.1901723549474807}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import cntk as C\n",
    "from cntk.learners import sgd, learning_rate_schedule, UnitType\n",
    "from cntk.logging import ProgressPrinter\n",
    "from cntk.layers import Dense, Sequential\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "def generate_random_data(sample_size, feature_dim, num_classes):\n",
    "     # Create synthetic data using NumPy.\n",
    "     Y = np.random.randint(size=(sample_size, 1), low=0, high=num_classes)\n",
    "\n",
    "     # Make sure that the data is separable\n",
    "     X = (np.random.randn(sample_size, feature_dim) + 3) * (Y + 1)\n",
    "     X = X.astype(np.float32)\n",
    "     # converting class 0 into the vector \"1 0 0\",\n",
    "     # class 1 into vector \"0 1 0\", ...\n",
    "     class_ind = [Y == class_number for class_number in range(num_classes)]\n",
    "     Y = np.asarray(np.hstack(class_ind), dtype=np.float32)\n",
    "     return X, Y\n",
    "\n",
    "def ffnet(args):\n",
    "    lr, hd = args\n",
    "    inputs = 2\n",
    "    outputs = 2\n",
    "    layers = 2\n",
    "    hidden_dimension = hd\n",
    "\n",
    "    # input variables denoting the features and label data\n",
    "    features = C.input((inputs), np.float32)\n",
    "    label = C.input((outputs), np.float32)\n",
    "\n",
    "    # Instantiate the feedforward classification model\n",
    "    my_model = Sequential ([\n",
    "                    Dense(hidden_dimension, activation=C.sigmoid),\n",
    "                    Dense(outputs)])\n",
    "    z = my_model(features)\n",
    "\n",
    "    ce = C.cross_entropy_with_softmax(z, label)\n",
    "    pe = C.classification_error(z, label)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_minibatch = learning_rate_schedule(lr, UnitType.minibatch)\n",
    "    progress_printer = ProgressPrinter(0)\n",
    "    trainer = C.Trainer(z, (ce, pe), [sgd(z.parameters, lr=lr_per_minibatch)], [progress_printer])\n",
    "\n",
    "    # Get minibatches of training data and perform model training\n",
    "    minibatch_size = 25\n",
    "    num_minibatches_to_train = 1024\n",
    "    aggregate_loss = 0.0\n",
    "    print (\"Learning rate \", lr, \"; Hidden dimension \", hd)\n",
    "    for i in range(num_minibatches_to_train):\n",
    "        train_features, labels = generate_random_data(minibatch_size, inputs, outputs)\n",
    "        # Specify the mapping of input variables in the model to actual minibatch data to be trained with\n",
    "        trainer.train_minibatch({features : train_features, label : labels})\n",
    "        sample_count = trainer.previous_minibatch_sample_count\n",
    "        aggregate_loss += trainer.previous_minibatch_loss_average * sample_count\n",
    "\n",
    "    last_avg_error = aggregate_loss / trainer.total_number_of_samples_seen\n",
    "\n",
    "    test_features, test_labels = generate_random_data(minibatch_size, inputs, outputs)\n",
    "    avg_error = trainer.test_minibatch({features : test_features, label : test_labels})\n",
    "    print(' error rate on an unseen minibatch: {}'.format(avg_error))\n",
    "    return avg_error\n",
    "\n",
    "np.random.seed(98052)\n",
    "trials = Trials()\n",
    "best = fmin(ffnet,\n",
    "    space=[hp.uniform('lr', 0.1, 0.2), hp.quniform('hd', 20, 100, 10)],\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=10,\n",
    "    trials=trials)\n",
    "\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
